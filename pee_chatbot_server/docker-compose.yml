version: "3.9"

services:
  llm_api:
    container_name: "llm_api_calm"
    build:
      context: ../pee_chatbot_LLM_CALM/
      dockerfile: ./Dockerfile
    volumes:
      - type: bind
        source: ../pee_chatbot_LLM_CALM/.
        target: /app
    ports:
      - 8008:8008
    environment:
      - DOWNLOAD_MODEL=false
    networks:
      chatbot_network:
        ipv4_address: 192.168.50.2
  chatbot_server:
    container_name: "chatbot_srv"
    build: .
    command: ["poetry", "run", "python", "app/main.py"]
    volumes:
      - type: bind
        source: .
        target: /work
    ports:
      - 8000:8000
    environment:
      OPENCALM_SERVER_HOST: http://192.168.50.2:8008
    networks:
      chatbot_network:
        ipv4_address: 192.168.50.3

networks:
  chatbot_network:
    ipam:
      driver: default
      config:
        - subnet: 192.168.50.0/24
